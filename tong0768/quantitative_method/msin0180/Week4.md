# 第4周课程：约束与数值优化

## 第1页
**第4周**  
约束与数值优化

MSIN00180 商业定量方法

---

## 第2页
**主题**
- 拉格朗日乘数法
- 特定方向的变化估计
- 线性化
- 泰勒级数
- 梯度下降算法
- 牛顿法

---

## 第3页
### 拉格朗日乘数法
考虑函数 \( f(x, y) = \sqrt{y - x^2} \)  
约束条件为直线 \( y = x + 2 \)。

在最大值点处，函数 \( f \) 的**梯度向量**与约束线 \( y = x + 2 \) **正交**。  
解得极值点：\( x = 0.405, \, y = 2.405 \)。

---

## 第4页
### 拉格朗日乘数法
将约束 \( y = x + 2 \) 表示为 \( g(x, y) = y - x - 2 = 0 \)，其梯度为：  
\[
\nabla g = (-1, 1)
\]  
在极值点处，\(\nabla f\) 与 \(\nabla g\) 平行，即存在标量 \(\lambda\) 使得：  
\[
\nabla f = \lambda \nabla g
\]  
这是拉格朗日乘数法的基础。

---

## 第5页
### 拉格朗日乘数法步骤
设 \( f(x, y) \) 和 \( g(x, y) \) 可微，且在约束 \( g(x, y) = 0 \) 处 \(\nabla g \neq 0\)。  
求解以下方程组：  
\[
\nabla f = \lambda \nabla g \quad \text{和} \quad g(x, y) = 0
\]  
多变量情形需扩展方程数量。

---

## 第6页
### 示例1
求 \( f(x, y) = \sqrt{y - x^2} \) 在约束 \( y = x + 2 \) 下的极值。  
梯度计算：  
\[
\nabla f = \left( \frac{-x}{\sqrt{y-x^2}}, \frac{1}{2\sqrt{y-x^2}} \right), \quad \nabla g = (-1, 1)
\]  
解得 \( x = \frac{1}{2}, \, y = \frac{5}{2} \)，极值为 \( \frac{3}{2} \)。

---

## 第7页
### Mathematica 的 Maximize 函数
代码示例：
```mathematica
Maximize[{Sqrt[y - x^2], y == x + 2}, {x, y}]
```  
输出结果为极值 \( \frac{3}{2} \)，对应点 \( (x = \frac{1}{2}, y = \frac{5}{2}) \)。

---

## 第8-10页
### 示例2
求 \( f(x, y) = xy \) 在椭圆边界 \( \frac{x^2}{8} + \frac{y^2}{2} = 1 \) 上的极值。  
解得四个极值点：\( (2, 1), (-2, -1) \)（最大值 2），\( (-2, 1), (2, -1) \)（最小值 -2）。

---

## 第11-14页
### 双约束拉格朗日乘数法
目标：求原点到两平面 \( y + 2z = 12 \) 和 \( x + y = 6 \) 交线的最小距离。  
解得最近点为 \( (2, 4, 4) \)，距离为 6。

---

## 第15-19页
### 特定方向的变化估计
公式：  
\[
df = (\nabla f \cdot \mathbf{u}) \, ds
\]  
示例：分析企业利润随定价和销量的变化，梯度计算为 \( \nabla p = (2, 10, 2000) \)，方向向量 \( \mathbf{u} = (-1, 0, 0.01) \)，估算利润变化为 +90。

---

## 第20-26页
### 线性化
函数 \( f(x) \) 在 \( x = a \) 处的线性化：  
\[
L(x) = f(a) + f'(a)(x - a)
\]  
二维函数 \( f(x, y) \) 的线性化：  
\[
L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)
\]

---

## 第27-29页
### 线性化误差
### 第27页详细解释：线性化估计的误差分析

---

#### **1. 线性化误差的定义**
线性化是用切线或切平面近似原函数，但在远离参考点时会产生误差。  
定义**误差函数 \( E(x, y) \)** 为：  
\[
E(x, y) = f(x, y) - L(x, y)
\]  
其中 \( L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0) \)。

---

#### **2. 误差上界公式**
误差的绝对值满足不等式：  
\[
\left| E(x, y) \right| \leq \frac{M}{2} \left( |x - x_0| + |y - y_0| \right)^2
\]  
**参数说明**：
- \( M = \max\{|f_{xx}|, |f_{yy}|, |f_{xy}|\} \)，即二阶偏导数的最大绝对值。
- \( |x - x_0| + |y - y_0| \) 是点 \((x, y)\) 到参考点 \((x_0, y_0)\) 的曼哈顿距离。

---

#### **第30页 | PDF MSINO180 Week 4 Lecture.nb**

##### 多项式近似（Polynomial Approximations）
首先考虑函数 \( f(x) = e^x \) 在点 \( x_0 = 0 \) 处的线性化：  
\[
L(x) = f(x_0) + f'(x_0)(x - x_0) = e^0 + e^0(x - 0) = 1 + x
\]

**Mathematica输出示例**：
```mathematica
Out[-1+]:
6
4
2
-2
-1
1
2

\( e^x \)
\( 1 + x \)
```

---

#### **第31页**
##### 多项式近似（续）
二阶多项式（即二次函数）\( g(x) = ax^2 + bx + c \) 在 \( x_0 = 0 \) 处对 \( f(x) \) 的局部近似需满足以下条件：
1. \( g(x_0) = f(x_0) \)
2. \( g'(x_0) = f'(x_0) \)
3. \( g''(x_0) = f''(x_0) \)

**具体推导**：
- \( g(x_0) = f(x_0) \rightarrow ax_0^2 + bx_0 + c = e^{x_0} \rightarrow a \cdot 0 + b \cdot 0 + c = 1 \rightarrow c = 1 \)。
- \( g'(x_0) = f'(x_0) \rightarrow 2ax_0 + b = e^{x_0} \rightarrow b = 1 \)。
- \( g''(x_0) = f''(x_0) \rightarrow 2a = e^{x_0} \rightarrow a = \frac{1}{2} \)。

最终得到近似多项式：  
\[
g(x) = \frac{1}{2}x^2 + x + 1
\]

---

#### **第32页**
##### 高阶多项式近似
通过类似方法可以推导出更高阶的近似多项式，例如：  
\[
e^x = h(x) = \frac{1}{3!}x^3 + \frac{1}{2!}x^2 + x + 1
\]  
**Mathematica输出示例**：
```mathematica
Out[j+]:
更高阶展开...
```

---

#### **第33页**
##### 泰勒级数（Taylor Series）
对任意可微函数 \( f(x) \)，其在点 \( x = x_0 \) 处的泰勒级数展开为：  
\[
f(x) \approx f(x_0) + f'(x_0)(x - x_0) + \frac{1}{2}f''(x_0)(x - x_0)^2 + \frac{1}{6}f'''(x_0)(x - x_0)^3 + \cdots
\]  
一般形式为：  
\[
f(x) \approx f(x_0) + \sum_{n=1}^{\infty} \frac{1}{n!} f^{(n)}(x_0)(x - x_0)^n
\]

---

#### **第34页**
##### 麦克劳林级数（Maclaurin Series）
当泰勒级数的中心 \( x_0 = 0 \) 时，称为麦克劳林级数：  
\[
f(x) \approx f(0) + \sum_{n=1}^\infty \frac{1}{n!} f^{(n)}(0) x^n
\]

---

#### **第35页**
##### 示例：二阶麦克劳林多项式
对函数 \( f(x) = \frac{1}{\sqrt{1 - x^2}} \)，其二阶麦克劳林近似为：  
\[
f(x) \approx 1 + \frac{1}{2}x^2
\]  
**推导步骤**：
1. \( f(0) = 1 \)。
2. \( f'(x) = \frac{x}{(1 - x^2)^{3/2}} \rightarrow f'(0) = 0 \)。
3. \( f''(x) = \frac{1}{(1 - x^2)^{3/2}} + \frac{3x^2}{(1 - x^2)^{5/2}} \rightarrow f''(0) = 1 \)。

---

#### **第36页**
##### Mathematica绘图示例
```mathematica
Plot[\(\frac{1}{\sqrt{1 - x^2}}, 1 + \frac{x^2}{2}\), {x, -1, 1}, PlotRange -> {0, 2}]
```
**输出图像**：
- 在 \( x = 0 \) 附近，\( 1 + \frac{x^2}{2} \) 与 \( \frac{1}{\sqrt{1 - x^2}} \) 高度吻合。

---

#### **第42页**
##### 梯度下降算法（Gradient Descent Algorithm）
**核心思想**：通过迭代沿负梯度方向更新参数，逐步逼近函数的局部最小值。  
**算法步骤**：
1. 初始化起点 \( x_0 \)、学习率 \( \eta \)、精度 \( \delta \)。
2. 计算梯度 \( \nabla f(x_t) \)，更新 \( x_{t+1} = x_t - \eta \nabla f(x_t) \)。
3. 当 \( |x_t - x_{t+1}| < \delta \) 时停止。

**Python代码示例**：
```python
def gradient_descent(f, grad_f, x0, eta=0.1, max_iter=1000):
    x = x0
    for _ in range(max_iter):
        x = x - eta * grad_f(x)
    return x
```

---

#### **第53-57页**
##### 牛顿法（Newton's Method）
**用于求方程的根**，迭代公式：  
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\]  
**示例**：求解 \( x^3 - x - 1 = 0 \)，初始猜测 \( x_0 = 1.5 \)，迭代收敛至根 \( x \approx 1.32472 \)。

**Mathematica代码**：
```mathematica
NewtonRoot[f_, x0_, n_] := Module[{x = x0}, Do[x = x - f[x]/f'[x], n]; x]
NewtonRoot[#^3 - # - 1 &, 1.5, 5] (* 输出：1.32472 *)
```

---

**注意**：公式、代码及专业术语保留英文原样以确保准确性，解释性内容已翻译为中文。