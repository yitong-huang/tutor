#### **第5-9页**
**机器学习范式**
1. **训练数据**：用于模型学习的已知数据。
2. **测试数据**：与训练数据同分布的新数据，用于评估模型性能。
3. **训练过程**：通过优化算法（如梯度下降）调整模型参数。
4. **预测**：模型对新数据的输出。
5. **评估**：比较预测结果与真实标签。

**监督学习 vs 无监督学习**
- **监督学习**：输入数据带标签（如分类、回归）。
- **无监督学习**：输入数据无标签（如聚类、关联分析）。

---

#### **第13-18页**
**分类（Classification）**
1. **定义**: 通过特征向量 \( x \in \mathbb{R}^n \) 预测类别标签 \( y \in \{1, ..., c\} \)。
2. **目标函数**: 找到映射 \( f: \mathbb{R}^n \to \{1, ..., c\} \)。

**鸢尾花数据集示例**
- **特征**: 萼片长度、萼片宽度、花瓣长度、花瓣宽度。
- **类别**: Setosa、Versicolor、Virginica。

---

#### **第19-34页**
**K-近邻算法（KNN）**
1. **原理**:
    - 对测试样本，找到训练集中距离最近的 \( k \) 个样本，根据多数投票确定类别。
    - **距离度量**：欧氏距离（默认）、曼哈顿距离、余弦相似度等。

2. **示例**:
    - 给定测试样本的特征向量，计算与所有训练样本的距离，选择最近的 \( k \) 个邻居。
    - **问题**: 当 \( k=1 \) 时，模型对噪声敏感；增大 \( k \) 可提高鲁棒性。

---

#### **第36-49页**
**常用距离度量**
1. **欧氏距离**:  
   \[
   \|a - b\|_2 = \sqrt{\sum_i (a_i - b_i)^2}
   \]
2. **曼哈顿距离**:  
   \[
   \|a - b\|_1 = \sum_i |a_i - b_i|
   \]
3. **余弦相似度**:  
   \[
   \text{similarity} = \frac{\sum a_i b_i}{\sqrt{\sum a_i^2} \sqrt{\sum b_i^2}}
   \]
4. **汉明距离**: 用于字符串差异计数。

---

#### **第51-66页**
**模型评估指标**
1. **准确率（Accuracy）**:  
   \[
   \text{Accuracy} = \frac{\text{正确预测数}}{\text{总样本数}}
   \]
2. **混淆矩阵**:
    - TP（真阳性）、TN（真阴性）、FP（假阳性）、FN（假阴性）。
3. **灵敏度（Recall）**:  
   \[
   \text{Sensitivity} = \frac{TP}{TP + FN}
   \]
4. **特异性（Specificity）**:  
   \[
   \text{Specificity} = \frac{TN}{TN + FP}
   \]
5. **F1分数**: 精确率与灵敏度的调和平均。

---

#### **第73-99页**
**聚类（Clustering）**
1. **目标**: 将数据划分为内部相似、外部相异的群组。
2. **K-Means算法**:
    - **步骤**:
        1. 随机初始化 \( k \) 个质心。
        2. 将每个点分配到最近的质心。
        3. 重新计算质心（簇内均值）。
        4. 重复直至质心稳定。
    - **挑战**: 需预先指定 \( k \)，初始质心影响结果。

3. **肘部法则（Elbow Method）**:
    - 通过不同 \( k \) 值的簇内方差（WCSS）曲线，选择拐点作为最佳 \( k \)。

---

### 题目

#### 2021-22 Question 1.b knn

#### 2021-22 Question 3.b kmeans




