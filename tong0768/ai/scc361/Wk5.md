#### **第55-91页**
**Naïve Bayes**

贝叶斯理论 第65页

贝叶斯分类 第68页

例子 第73页

连续值求P 第82页

---

### 题目

#### 2020-21 Question 3.c

---

####  **第91页**
**SVM**

### 翻译（第94页之后内容）

#### 第94页
# 支持向量机（SVM）

---

#### 第95页
# 空间划分
设 \( x_1 \in \mathbb{R}^m, x_2 \in \mathbb{R}^n \) 为连续值特征向量，假设为二分类问题：  
\[
f(x_1, x_2) =
\begin{cases}
0 & \text{若分类为 } 0 \\
1 & \text{若分类为 } 1
\end{cases}
\]

**问题**：数据是否线性可分？  
即能否找到一条直线：  
\[
L(x_1, x_2): \alpha_1 x_1 + \alpha_2 x_2 + \alpha_3 = 0 \quad (\alpha_1, \alpha_2, \alpha_3 \in \mathbb{R})
\]  
将两类数据分开？

若可分，则分类规则为：  
\[
f(x_1, x_2) =
\begin{cases}
0 & \text{若 } L(x_1, x_2) < 0 \\
1 & \text{若 } L(x_1, x_2) > 0
\end{cases}
\]

---

#### 第96页
**数据非线性可分时的处理**
- 使用非线性核函数（如多项式核、高斯核）将数据映射到高维空间，使其线性可分。
- 示例图显示二维空间中非线性可分的数据点分布。

---

#### 第97页
# SVM的构建
**问题定义**  
每个样本 \( X_i \) 包含数据 \( x_i \) 和标签 \( y_i \)：  
\[
X_i = (x_i, y_i), \quad y_i =
\begin{cases}
1 & \text{若 } X_i \in S_1 \\
-1 & \text{若 } X_i \in S_2
\end{cases}
\]  
其中 \( x_i \) 是 \( p \) 维实向量。

---

#### 第98页
**SVM的核心思想**  
寻找一个“最大间隔超平面”，将两类数据分开，使得超平面到最近数据点的距离（间隔）最大化。

---

#### 第99页
# 超平面与间隔
**超平面方程**：  
\[
w^T x - b = 0 \quad (w \text{ 为法向量}, b \text{ 为偏置})
\]
- 间隔（Margin）是两类数据到超平面的最小距离之和。
- **最大间隔超平面**是位于两个平行超平面中间的最优分类面。

---

#### 第100页
**定义间隔超平面**  
\[
\begin{aligned}
h_1: & \quad w^T x - b = 1 \\
h_2: & \quad w^T x - b = -1
\end{aligned}
\]  
间隔距离为：  
\[
\text{间隔} = \frac{2}{\|w\|}
\]  
目标是最小化 \( \|w\| \) 以最大化间隔。

---

#### 第101-103页
**约束条件**  
所有样本需满足：  
\[
y_i(w^T x_i - b) \geq 1 \quad (i = 1, 2, ..., n)
\]  
**优化问题**：  
\[
\min_{w, b} \frac{1}{2} \|w\|^2 \quad \text{满足} \quad y_i(w^T x_i - b) \geq 1
\]

---

#### 第104页
**核技巧（Kernel Trick）**  
通过核函数将数据映射到高维空间，解决非线性可分问题。常用核函数：
- **线性核**：\( k(x_i, x_j) = x_i \cdot x_j \)
- **多项式核**：\( k(x_i, x_j) = (x_i \cdot x_j)^p \)
- **高斯核（RBF）**：\( k(x_i, x_j) = \exp(-\gamma \|x_i - x_j\|^2) \)
- **Sigmoid核**：\( k(x_i, x_j) = \tanh(k_1 + k_2 x_i \cdot x_j) \)

---

### 详细解释

#### 1. SVM的核心思想
SVM是一种监督学习算法，目标是找到一个超平面，将不同类别的数据分开，并使得两类数据到超平面的间隔最大化。间隔越大，模型的泛化能力越强。

#### 2. 超平面与间隔
- **超平面**：在 \( p \) 维空间中的 \( p-1 \) 维子空间。例如，二维空间中是一条直线，三维空间中是一个平面。
- **间隔**：超平面到最近数据点的距离。最大化间隔可减少过拟合风险。

#### 3. 优化问题
通过最小化 \( \|w\| \)（即正则化项）来最大化间隔，同时满足所有样本正确分类的约束条件 \( y_i(w^T x_i - b) \geq 1 \)。

#### 4. 核技巧
当数据线性不可分时，核函数将数据映射到高维空间，使其在高维空间中线性可分。例如，高斯核通过径向基函数将数据映射到无限维空间。

#### 5. 应用场景
- 图像分类（如手写数字识别）
- 文本分类（如垃圾邮件检测）
- 生物信息学（如基因分类）

#### 6. 数学公式的意义
- \( w^T x - b = 0 \)：分类超平面方程。
- \( \frac{2}{\|w\|} \)：间隔距离，优化目标是最大化该值。
- 核函数：通过内积计算隐式映射到高维空间，避免显式计算高维特征。

---

### 示例图说明
- **线性可分**：二维平面上用一条直线分开两类点。
- **非线性可分**：通过核函数映射后，在高维空间用超平面分开（如螺旋形数据）。

通过以上方法，SVM能够有效处理线性和非线性分类问题，并在高维数据中表现优异。

---

### 题目

#### 2022-23 Question 3.c 3.d

### 支持向量机（SVM）的分类方法及核技巧的作用

#### 1. **SVM 如何划分数据点并实现分类？**
- **核心思想**：  
  SVM 的目标是找到一个最优超平面（hyperplane），将不同类别的数据点分开，同时最大化两类数据到超平面的最小距离（即**间隔**）。这个超平面的选择基于“间隔最大化”原则，使得分类结果对未知数据的泛化能力更强。
- **数学描述**：  
  超平面方程为 \( w^T x + b = 0 \)，其中 \( w \) 是法向量，\( b \) 是偏置项。
    - 对于线性可分数据，SVM 通过以下优化问题求解 \( w \) 和 \( b \)：  
      \[
      \min_{w,b} \frac{1}{2} \|w\|^2 \quad \text{满足} \quad y_i(w^T x_i + b) \geq 1 \quad (\forall i)
      \]
    - **支持向量**：离超平面最近的样本点，它们决定了超平面的位置和间隔大小。

- **分类结果**：  
  新样本 \( x \) 的分类由符号函数决定：  
  \[
  \text{分类} = \text{sign}(w^T x + b)
  \]
  若结果为正，则属于正类；若为负，则属于负类。

---

#### 2. **核技巧的作用及两种常见核函数**
- **为什么需要核技巧？**  
  当数据在原始特征空间中**线性不可分**时（例如数据分布呈环形或螺旋形），直接使用线性超平面无法有效分类。核技巧通过将数据隐式映射到更高维的空间，使其在高维空间中线性可分，从而解决非线性问题。

- **两种核函数示例**：
    1. **多项式核（Polynomial Kernel）**  
       \[
       K(x_i, x_j) = (x_i \cdot x_j + c)^d
       \]
        - **作用**：通过多项式组合特征，捕捉数据中的非线性关系。
        - **参数**：\( d \) 控制多项式阶数，\( c \) 为常数项。
        - **示例**：当 \( d=2 \)，可将二维数据映射到三维空间，使螺旋数据可分。

    2. **高斯核（RBF，径向基函数核）**  
       \[
       K(x_i, x_j) = \exp\left(-\gamma \|x_i - x_j\|^2\right)
       \]
        - **作用**：通过衡量样本间的相似性，将数据映射到无限维空间，适合复杂边界。
        - **参数**：\( \gamma \) 控制高斯函数的宽度，值越大对局部细节越敏感。

- **核技巧如何提升分类效果？**
    - **非线性可分问题**：通过映射到高维空间，将原始空间中复杂的决策边界转化为高维空间中的线性超平面。
    - **灵活性**：核函数隐式计算高维空间的内积，避免显式映射的计算成本（“核技巧”的巧妙之处）。
    - **示例**：  
      原始空间中环形分布的数据，经高斯核映射后，在高维空间中可用一个超平面分开（如图）。

---

#### 3. **总结**
- **SVM 的优势**：
    - 间隔最大化提高泛化能力，避免过拟合。
    - 核技巧灵活处理非线性问题，适应复杂数据分布。
- **核函数的选择**：  
  需根据数据特点调整核类型及参数（如 \( \gamma \)、\( d \)），实践中常用交叉验证优化。

通过结合间隔最大化和核技巧，SVM 既能高效处理线性分类，又能解决高度非线性的实际问题（如图像识别、文本分类等），成为机器学习中的经典算法。

---
